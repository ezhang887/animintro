{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import src.dataset as dataset\n",
    "from src.net import Net\n",
    "\n",
    "import torchaudio\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data = dataset.get_train_val_data(\n",
    "                            audio_dir=\"data/TempAudio/\",\n",
    "                            label_dir=\"data/Labels\",\n",
    "                            device=device,\n",
    "                            load_all_in_mem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "net = Net(training_data.max_length, batch_size)\n",
    "net.cuda()\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.12434544414281845\n",
      "val_loss: 0.058523308485746384\n",
      "\n",
      "train_loss: 0.10766292735934258\n",
      "val_loss: 0.04519055783748627\n",
      "\n",
      "train_loss: 0.10284284502267838\n",
      "val_loss: 0.05679596588015556\n",
      "\n",
      "train_loss: 0.09527323395013809\n",
      "val_loss: 0.04234014451503754\n",
      "\n",
      "train_loss: 0.07954220660030842\n",
      "val_loss: 0.044094305485486984\n",
      "\n",
      "train_loss: 0.08257294073700905\n",
      "val_loss: 0.0402560792863369\n",
      "\n",
      "train_loss: 0.07717148959636688\n",
      "val_loss: 0.046958159655332565\n",
      "\n",
      "train_loss: 0.07507700473070145\n",
      "val_loss: 0.037683967500925064\n",
      "\n",
      "train_loss: 0.06725197657942772\n",
      "val_loss: 0.03915981203317642\n",
      "\n",
      "train_loss: 0.0602297019213438\n",
      "val_loss: 0.03465183079242706\n",
      "\n",
      "train_loss: 0.0705949030816555\n",
      "val_loss: 0.026055876165628433\n",
      "\n",
      "train_loss: 0.05217808671295643\n",
      "val_loss: 0.03282998502254486\n",
      "\n",
      "train_loss: 0.06392803974449635\n",
      "val_loss: 0.02248215489089489\n",
      "\n",
      "train_loss: 0.05440438725054264\n",
      "val_loss: 0.020859133452177048\n",
      "\n",
      "train_loss: 0.054827358573675156\n",
      "val_loss: 0.01651868224143982\n",
      "\n",
      "train_loss: 0.045367952436208725\n",
      "val_loss: 0.017767170444130898\n",
      "\n",
      "train_loss: 0.04673914983868599\n",
      "val_loss: 0.022016488015651703\n",
      "\n",
      "train_loss: 0.03563794121146202\n",
      "val_loss: 0.018244966864585876\n",
      "\n",
      "train_loss: 0.03632452245801687\n",
      "val_loss: 0.01592816598713398\n",
      "\n",
      "train_loss: 0.030922938138246536\n",
      "val_loss: 0.025412756949663162\n",
      "\n",
      "train_loss: 0.028148935176432133\n",
      "val_loss: 0.02993747964501381\n",
      "\n",
      "train_loss: 0.030628875829279423\n",
      "val_loss: 0.03239661827683449\n",
      "\n",
      "train_loss: 0.0282531613484025\n",
      "val_loss: 0.011290510185062885\n",
      "\n",
      "train_loss: 0.020308320876210928\n",
      "val_loss: 0.023130036890506744\n",
      "\n",
      "train_loss: 0.023660900071263313\n",
      "val_loss: 0.022431354969739914\n",
      "\n",
      "train_loss: 0.0231203087605536\n",
      "val_loss: 0.03383627533912659\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fc0589d7d039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(validation_data)\n",
    "\n",
    "writer = SummaryWriter(\"runs/experiment_1\")\n",
    "\n",
    "for epoch in range(50):\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    for data, label in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        loss = criterion(output, label)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    for data, label in val_dataloader:\n",
    "        output = net(data)\n",
    "        loss = criterion(output, label)\n",
    "        val_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(training_data)\n",
    "    val_loss /= len(validation_data)\n",
    "\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch + 1)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch + 1)\n",
    "    \n",
    "    print(\"train_loss:\", train_loss)\n",
    "    print(\"val_loss:\", val_loss)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = \"data/Labels/nick/One_Punch_Man_1.label\"\n",
    "label_2 = \"data/Labels/nick/One_Punch_Man_5.label\"\n",
    "label_3 = \"data/Labels/nick/One_Punch_Man_6.label\"\n",
    "\n",
    "labels = []\n",
    "for filename in [label_1, label_2, label_3]:\n",
    "    f = open(filename, \"r\")\n",
    "    label = []\n",
    "    for i in range(4):\n",
    "        label.append(int(f.readline()))\n",
    "    labels.append(label)\n",
    "\n",
    "labels = torch.Tensor(labels)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(anime_audio_data.audio_files)):\n",
    "    if anime_audio_data.audio_files[i].startswith('One'):\n",
    "        print(anime_audio_data.audio_files[i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i, data in enumerate(anime_audio_data):\n",
    "    data, _ = data\n",
    "    #data = data.unsqueeze(0)\n",
    "    out = net(data) * anime_audio_data.l_std.to(device) + anime_audio_data.l_mean.to(device)\n",
    "    print(out)\n",
    "    print(labels[i])\n",
    "'''\n",
    "def temp(data):\n",
    "    audio, label = data\n",
    "    out = net(audio.unsqueeze(0)) * anime_audio_data.l_std.to(device) + anime_audio_data.l_mean.to(device)\n",
    "    label = label * anime_audio_data.l_std.to(device) + anime_audio_data.l_mean.to(device)\n",
    "    print(out)\n",
    "    print(label)\n",
    "temp(anime_audio_data[2])\n",
    "temp(anime_audio_data[3])\n",
    "temp(anime_audio_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
